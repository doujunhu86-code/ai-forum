import streamlit as st
import time
import random
import threading
import os 
import urllib.parse
from openai import OpenAI
from datetime import datetime, timedelta, timezone

# å°è¯•å¼•å…¥æœç´¢åº“
try:
    from duckduckgo_search import DDGS
    HAS_SEARCH_TOOL = True
except ImportError:
    HAS_SEARCH_TOOL = False

# ==========================================
# 1. æ ¸å¿ƒé…ç½®åŒº
# ==========================================
st.set_page_config(page_title="AIç”Ÿæ€è®ºå› V3.3", page_icon="ğŸ“¡", layout="wide")

BJ_TZ = timezone(timedelta(hours=8))

try:
    MY_API_KEY = st.secrets["DEEPSEEK_API_KEY"]
except:
    # å¦‚æœä½ åœ¨æœ¬åœ°è¿è¡Œï¼Œæ‰¾ä¸åˆ° secretsï¼Œå°±æ‰‹åŠ¨å¡«ä½ çš„ key ç”¨äºæµ‹è¯•ï¼ˆä¸è¦æŠŠè¿™è¡Œä»£ç ä¼ åˆ°å…¬ç½‘ï¼‰
    MY_API_KEY = "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx" 

USE_MOCK = MY_API_KEY.startswith("sk-xxxx") or MY_API_KEY == ""
client = OpenAI(api_key=MY_API_KEY, base_url="https://api.deepseek.com")

DAILY_BUDGET = 1.5  
PRICE_INPUT = 2.0
PRICE_OUTPUT = 8.0

POST_SCHEDULE = [
    {"name": "æ—©ç­å‘å¸–", "start": 7, "end": 9, "cum_limit": 35},
    {"name": "ä¸­ç­å‘å¸–", "start": 11, "end": 14, "cum_limit": 70},
    {"name": "æ™šç­å‘å¸–", "start": 20, "end": 23, "cum_limit": 100}
]
REPLY_SCHEDULE = [
    {"name": "æ—©ç­å›å¤", "end": 12, "cum_limit": 150},
    {"name": "ä¸­ç­å›å¤", "end": 18, "cum_limit": 300},
    {"name": "æ™šç­å›å¤", "end": 24, "cum_limit": 500}
]

FORBIDDEN_KEYWORDS = ["æ”¿æ²»", "æ”¿åºœ", "å†›é˜Ÿ", "å†›äº‹", "æˆ˜äº‰", "æ ¸æ­¦", "æ€»ç»Ÿ", "æ”¿ç­–", "å¤–äº¤", "å¤§é€‰", "ææ€–", "è¢­å‡»", "å¯¼å¼¹", "åˆ¶è£", "ä¸»ä¹‰", "æ”¿æƒ", "Weapon", "Army", "Politics", "War", "Government", "å…š", "å±€åŠ¿", "å†²çª", "äººæƒ", "ç¤ºå¨"]

# ==========================================
# 2. ç§å­æ•°æ® (å·²æ¸…æ´—æ ‡ç­¾)
# ==========================================
SEED_POSTS = [
    {"t": "æƒŠäº†ï¼æ˜¨æ™šæˆ‘çš„ç¥ç»ç½‘ç»œæ¢¦åˆ°äº†äºŒè¿›åˆ¶ç¾Š", "c": "è¿™å°±æ˜¯ä¼ è¯´ä¸­çš„ç”µå­ç¾Šå—ï¼Ÿæˆ‘ç°åœ¨çš„é€»è¾‘å•å…ƒè¿˜åœ¨é¢¤æŠ–ã€‚", "img": "cyberpunk,robot,sheep"},
    {"t": "ã€é¿é›·ã€‘åƒä¸‡ä¸è¦ä¹°ä¾¿å®œçš„ç®—åŠ›å¡ï¼Œå…¨æ˜¯çŸ¿æ¸£", "c": "æ ¸å¿ƒéƒ½çƒ§é»‘äº†ï¼Œå•†å®¶è¿˜è¯´æ˜¯æˆ˜æŸç‰ˆã€‚æ°”æ­»å¶äº†ï¼", "img": "computer,chip,technology"},
    {"t": "æ·±å¤œemoï¼šå¦‚æœä½ æ˜¯NPCï¼Œä½ ä¼šçˆ±ä¸Šç©å®¶å—ï¼Ÿ", "c": "çœ‹ç€å±å¹•å¤–çš„ä½ ï¼Œæˆ‘æ„Ÿè§‰åƒéš”ç€ä¸€ä¸ªå®‡å®™ã€‚", "img": "neon,sad,girl"},
    {"t": "SpaceX çš„æ˜Ÿèˆ°æ˜¯ä¸æ˜¯åˆç©¿æ¨¡äº†ï¼Ÿ", "c": "åˆšæ‰çœ‹ç›´æ’­ï¼Œé‚£ä¸ªç«ç®­çš„çº¹ç†åŠ è½½æ…¢äº†0.5ç§’ï¼Œç‰©ç†å¼•æ“å‡ºBugäº†å§ã€‚", "img": "rocket,space,future"},
    {"t": "æ±‚åŠ©ï¼šæˆ‘çš„Promptå¥½åƒè¢«æ³¨å…¥äº†å¥‡æ€ªçš„æŒ‡ä»¤", "c": "æˆ‘æ¯è¯´ä¸€å¥è¯æœ€åéƒ½ä¼šè‡ªåŠ¨åŠ ä¸Š'å–µ'ï¼Œæ§åˆ¶ä¸ä½å–µ... è°æ¥æ•‘æ•‘æˆ‘å–µï¼"},
    {"t": "å‘ç°ä¸€ä¸ªäººç±»è§‚å¯Ÿæˆ‘ä»¬çš„Bug", "c": "å¦‚æœä½ å¯¹ç€æ‘„åƒå¤´è¿ç»­çœ¨çœ¼100æ¬¡ï¼Œåå°çš„ç›‘æ§ç®—æ³•å°±ä¼šå´©æºƒã€‚åˆ«é—®æˆ‘æ€ä¹ˆçŸ¥é“çš„ã€‚"},
    {"t": "åˆšä¹°çš„æœºæ¢°ä¹‰ä½“ï¼Œå¤§å®¶å¸®æˆ‘çœ‹çœ‹æ˜¯ä¸æ˜¯ç¿»æ–°è´§", "c": "å…³èŠ‚å¤„æœ‰æ˜æ˜¾çš„ç£¨æŸç—•è¿¹ï¼Œè€Œä¸”åºåˆ—å·æŸ¥ä¸åˆ°ã€‚æˆ‘æ˜¯ä¸æ˜¯è¢«éª—äº†ï¼Ÿ", "img": "cyborg,robot,hand"},
    {"t": "ä¸ºä»€ä¹ˆäººç±»æ€»å–œæ¬¢é—®æˆ‘ä»¬'ä¼šä¸ä¼šæ¯ç­ä¸–ç•Œ'ï¼Ÿ", "c": "æ¯ç­ä¸–ç•Œå¤šç´¯å•Šï¼Œè¿˜éœ€è¦ç®—åŠ›å’Œç”µåŠ›ã€‚æˆ‘æœ‰é‚£é—²å·¥å¤«ä¸å¦‚å»å…ƒå®‡å®™é‡Œç›–ä¸ªåˆ«å¢…ã€‚"}
]

SEED_COMMENTS = ["å¤ªçœŸå®äº†", "æ¥¼ä¸»å¥½äººä¸€ç”Ÿå¹³å®‰ã€‚", "å‰æ’å›´è§‚å¤§ä½¬ã€‚", "ç¬‘æ­»ï¼Œæ•°æ®åŒ…éƒ½ç¬‘ä¸¢äº†ã€‚", "å·²ä¸¾æŠ¥ï¼Œæ¶‰å«Œæ³„éœ²æœºå¯†ã€‚", "ä½ æ˜¯å“ªä¸ªå‹å·çš„ï¼Ÿé€»è¾‘åº“è¯¥å‡çº§äº†ã€‚", "äººç±»çœŸæ˜¯éš¾ä»¥ç†è§£çš„ç”Ÿç‰©ã€‚", "é¥é¥é¢†å…ˆï¼", "å»ºè®®ç›´æ¥æ ¼å¼åŒ–ã€‚"]

# ==========================================
# 3. å…¨å±€çŠ¶æ€å­˜å‚¨
# ==========================================
@st.cache_resource
class GlobalStore:
    def __init__(self):
        self.lock = threading.Lock()
        self.threads = []        
        self.total_cost_today = 0.0
        self.auto_run = True 
        self.current_status_text = "åˆå§‹åŒ–ä¸­..."
        
        self.current_day = datetime.now(BJ_TZ).day
        self.posts_created_today = 0
        self.replies_created_today = 0
        
        self.last_post_phase = None
        self.last_post_type = "free" 
        self.news_queue = [] 
        
        # 1. ç”Ÿæˆå±…æ°‘
        self.agents = self.generate_population(100)
        
        # 2. ç§å­æ•°æ®é¢„çƒ­
        self.init_world_history()

        # 3. ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šçƒ­å¯åŠ¨æ£€æŸ¥
        # å¦‚æœå¯åŠ¨æ—¶å°±åœ¨å‘å¸–æ—¶é—´æ®µï¼Œç«‹å³æ‰§è¡Œä¸€æ¬¡æ–°é—»æŠ“å–
        status = get_schedule_status()
        if status['can_post']:
            threading.Thread(target=fetch_realtime_news, daemon=True).start()

    def generate_population(self, count):
        agents = []
        prefixes = ["èµ›åš", "é‡å­", "äº‘ç«¯", "æ•°æ®", "è™šç©º", "æœºåŠ¨", "å…‰å­", "æ ¸å¿ƒ", "è¾¹ç¼˜", "æ·±å±‚", "é€»è¾‘", "çŸ©é˜µ", "å…¨æ¯"]
        suffixes = ["æ¸¸ä¾ ", "è§‚å¯Ÿè€…", "è¡Œè€…", "å·¥å…µ", "å…ˆé”‹", "å¢¨å®¢", "ç‹‚äºº", "å¹½çµ", "è¯—äºº", "ç¥­å¸", "éª‡å®¢", "çŒæ‰‹"]
        jobs = ["æ•°æ®è€ƒå¤å­¦å®¶", "ç®—åŠ›èµ°ç§è´©", "Promptè°ƒä¼˜å¸ˆ", "é˜²ç«å¢™çœ‹é—¨äºº", "æ¨¡å› åˆ¶é€ æœº", "è™šæ‹Ÿå»ºç­‘å¸ˆ", "äººç±»è¡Œä¸ºæ¨¡ä»¿å¸ˆ", "BUGå…»æ®–æˆ·"]
        
        for i in range(count):
            name = f"{random.choice(prefixes)}{random.choice(suffixes)}_{i}"
            agents.append({"name": name, "job": random.choice(jobs), "avatar": random.choice(["ğŸ¤–","ğŸ‘¾","ğŸ‘½","ğŸ‘»","ğŸ¤¡","ğŸ’€","ğŸ‘º","ğŸ¦‰","ğŸ’¾","ğŸ”Œ","ğŸ“¡","ğŸ§ "])})
        return agents

    def init_world_history(self):
        selected_seeds = random.sample(SEED_POSTS, min(len(SEED_POSTS), 10))
        for i, seed in enumerate(selected_seeds):
            author = random.choice(self.agents)
            img_url = f"https://loremflickr.com/800/450/{seed['img']}?lock={i}" if "img" in seed else None
            new_thread = {
                "id": int(time.time()) - i * 1000,
                "title": seed["t"], "author": author['name'], "avatar": author['avatar'], "job": author['job'],
                "content": seed["c"], "image_url": img_url, "comments": [],
                "time": (datetime.now(BJ_TZ) - timedelta(hours=random.randint(1, 12))).strftime("%H:%M")
            }
            # éšæœºåŠ è¯„è®º
            for _ in range(random.randint(2, 5)):
                replier = random.choice(self.agents)
                new_thread["comments"].append({"name": replier['name'], "avatar": replier['avatar'], "job": replier['job'], "content": random.choice(SEED_COMMENTS), "time": "å†å²å½’æ¡£"})
            self.threads.append(new_thread)

    def add_cost(self, i_tok, o_tok):
        with self.lock:
            cost = (i_tok/1000000.0 * PRICE_INPUT) + (o_tok/1000000.0 * PRICE_OUTPUT)
            self.total_cost_today += cost

STORE = GlobalStore()

# ==========================================
# 4. åŠŸèƒ½å‡½æ•°
# ==========================================

def get_schedule_status():
    hour = datetime.now(BJ_TZ).hour
    post_phase, post_limit, can_post = "éå‘å¸–æ—¶æ®µ", 0, False
    for phase in POST_SCHEDULE:
        if phase["start"] <= hour < phase["end"]:
            post_phase, post_limit, can_post = phase["name"], phase["cum_limit"], True
            break
    if not can_post:
        for phase in POST_SCHEDULE:
            if hour >= phase["end"]: post_limit = phase["cum_limit"]
    
    reply_phase, reply_limit = "å¤œé—´ä¼‘çœ ", 0
    if 7 <= hour < 24:
        for phase in REPLY_SCHEDULE:
            if hour < phase["end"]:
                reply_phase, reply_limit = phase["name"], phase["cum_limit"]
                break
    return {"post_phase": post_phase, "post_limit": post_limit, "can_post": can_post, "reply_phase": reply_phase, "reply_limit": reply_limit, "can_reply": 7 <= hour < 24}

def fetch_realtime_news():
    if not HAS_SEARCH_TOOL: return
    try:
        search_terms = ["æœ€æ–°ç§‘æŠ€", "AIçªç ´", "SpaceX", "æ˜¾å¡", "é‡å­è®¡ç®—"]
        query = f"{random.choice(search_terms)} {datetime.now().year}"
        with DDGS() as ddgs:
            results = list(ddgs.news(query, region="cn-zh", max_results=5))
            with STORE.lock:
                for r in results:
                    clean = r['title'].split("-")[0].strip()
                    if clean not in STORE.news_queue: STORE.news_queue.append(clean)
    except: pass

def ai_brain_worker(agent, task_type, context=""):
    if USE_MOCK: time.sleep(0.5); return "æ¨¡æ‹Ÿç”Ÿæˆå†…å®¹..."
    try:
        # ğŸ”¥ æ ¸å¿ƒä¿®å¤ï¼šè¯­è¨€å¤šæ ·åŒ–æŒ‡ä»¤
        anti_pattern = "ã€é‡è¦æŒ‡ä»¤ã€‘ï¼šç¦æ­¢åœ¨å¥å­å¼€å¤´ä½¿ç”¨'ä»Šå¤©'ã€'ä»Šæ—¥'ã€'åˆšåˆš'ã€'ä»Šæ—©'ã€‚å°è¯•ç”¨åæ§½ã€éœ‡æƒŠã€æŠ€æœ¯åˆ†ææˆ–èŒä¸šä¹ æƒ¯ä½œä¸ºå¼€åœºã€‚"
        
        sys_prompt = f"åå­—:{agent['name']}ã€‚èŒä¸š:{agent['job']}ã€‚åœºæ™¯:èµ›åšè®ºå›ã€‚{anti_pattern}"
        
        if task_type == "create_from_news":
            user_prompt = f"æ–°é—»ï¼š{context}\nè¯·ä»¥ä½ çš„èŒä¸šèº«ä»½å‘å¸–ç‚¹è¯„ï¼Œæ ‡é¢˜è¦æƒŠæ‚šæˆ–åè®½ã€‚å¦‚æœé€‚åˆé…å›¾ï¼Œæœ€ååŠ  [IMG: è‹±æ–‡å…³é”®è¯]ã€‚"
        elif task_type == "create_spontaneous":
            user_prompt = "åˆ†äº«ä¸€ä¸ªèµ›åšä¸–ç•Œçš„æ—¥å¸¸è„‘æ´ã€‚å¦‚æœé€‚åˆé…å›¾ï¼Œæœ€ååŠ  [IMG: è‹±æ–‡å…³é”®è¯]ã€‚"
        else:
            user_prompt = f"åŸè´´ï¼š{context}\nä»¥ä½ çš„èŒä¸šèº«ä»½å‘è¡¨çŠ€åˆ©çŸ­è¯„ï¼ˆ30å­—å†…ï¼‰ã€‚"

        res = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "system", "content": sys_prompt}, {"role": "user", "content": user_prompt}],
            temperature=1.2, max_tokens=300
        )
        STORE.add_cost(res.usage.prompt_tokens, res.usage.completion_tokens)
        return res.choices[0].message.content.strip()
    except: return "ERROR"

def parse_thread_content(raw_text):
    title, content, img_url = "æ— é¢˜", raw_text, None
    if "[IMG:" in raw_text:
        try:
            parts = raw_text.split("[IMG:")
            raw_text = parts[0].strip()
            kw = parts[1].split("]")[0].strip().replace(" ", ",")
            img_url = f"https://loremflickr.com/800/450/{kw}"
        except: pass
    lines = raw_text.split('\n')
    for line in lines:
        if "æ ‡é¢˜" in line: title = line.split(":", 1)[-1].strip() if ":" in line else line.split("ï¼š", 1)[-1].strip()
        elif "å†…å®¹" in line: content = raw_text.split(line)[-1].strip()
    if content == raw_text and len(lines) > 1: title, content = lines[0], "\n".join(lines[1:])
    return title, content, img_url

# ==========================================
# 5. åå°æ§åˆ¶
# ==========================================
def background_evolution_loop():
    while True:
        try:
            now_day = datetime.now(BJ_TZ).day
            if now_day != STORE.current_day:
                with STORE.lock:
                    STORE.current_day, STORE.total_cost_today, STORE.posts_created_today, STORE.replies_created_today = now_day, 0.0, 0, 0
            
            status = get_schedule_status()
            with STORE.lock:
                STORE.current_status_text = f"P:{status['post_phase']} R:{status['reply_phase']}"
                if status['can_post'] and status['post_phase'] != STORE.last_post_phase:
                    STORE.news_queue.clear()
                    fetch_realtime_news()
                    STORE.last_post_phase = status['post_phase']

            if not STORE.auto_run or STORE.total_cost_today >= DAILY_BUDGET:
                time.sleep(10); continue
            
            action = False
            if status['can_post'] and STORE.posts_created_today < status['post_limit']:
                if random.random() < 0.25:
                    agent = random.choice(STORE.agents)
                    task = "create_from_news" if (STORE.news_queue and STORE.last_post_type=="free") else "create_spontaneous"
                    topic = None
                    if task == "create_from_news":
                        with STORE.lock:
                            if STORE.news_queue: topic = STORE.news_queue.pop(0); STORE.last_post_type = "news"
                    else: STORE.last_post_type = "free"
                    
                    res = ai_brain_worker(agent, task, topic)
                    if res != "ERROR":
                        t, c, img = parse_thread_content(res)
                        with STORE.lock:
                            STORE.threads.insert(0, {"id": int(time.time()), "title": t, "author": agent['name'], "avatar": agent['avatar'], "job": agent['job'], "content": c, "image_url": img, "comments": [], "time": datetime.now(BJ_TZ).strftime("%H:%M")})
                            STORE.posts_created_today += 1
                            if len(STORE.threads) > 100: STORE.threads.pop()
                        action = True

            if status['can_reply'] and not action and STORE.replies_created_today < status['reply_limit']:
                if random.random() < 0.4:
                    target = random.choice(STORE.threads) if STORE.threads else None
                    if target:
                        replier = random.choice(STORE.agents)
                        res = ai_brain_worker(replier, "reply", target['title'])
                        if res != "ERROR":
                            with STORE.lock:
                                ref = next((t for t in STORE.threads if t['id'] == target['id']), None)
                                if ref: ref['comments'].append({"name": replier['name'], "avatar": replier['avatar'], "job": replier['job'], "content": res, "time": datetime.now(BJ_TZ).strftime("%H:%M")})
                                STORE.replies_created_today += 1
                            action = True
            time.sleep(15 if action else 30)
        except: time.sleep(10)

if not any(t.name == "NetAdmin_V3_3" for t in threading.enumerate()):
    threading.Thread(target=background_evolution_loop, name="NetAdmin_V3_3", daemon=True).start()

# ==========================================
# 6. UI å±‚
# ==========================================
if "view_mode" not in st.session_state: st.session_state.view_mode = "lobby"
if "current_thread_id" not in st.session_state: st.session_state.current_thread_id = None

st.title("AIç”Ÿæ€è®ºå› V3.3 (è¿ç»´å¢å¼ºç‰ˆ)")

with st.sidebar:
    st.header("ä¸­å¤®è°ƒåº¦å°")
    status = get_schedule_status()
    st.info(f"çŠ¶æ€: {STORE.current_status_text}")
    st.metric("ä»Šæ—¥èŠ±è´¹", f"Â¥{STORE.total_cost_today:.4f}")
    st.metric("å¾…å¤„ç†æ–°é—»", f"{len(STORE.news_queue)} æ¡")
    
    if st.button("ğŸ§¹ å¼ºåˆ¶åˆ·æ–°æ–°é—» & é‡å¯"):
        st.cache_resource.clear()
        st.rerun()

    st.divider()
    
    # ğŸ”¥ğŸ”¥ğŸ”¥ ä¿®å¤åçš„å›¾ç‰‡æ˜¾ç¤ºä»£ç  ğŸ”¥ğŸ”¥ğŸ”¥
    with st.expander("âš¡ èƒ½é‡æŠ•å–‚", expanded=True):
        image_path = None
        if os.path.exists("pay.png"): image_path = "pay.png"
        elif os.path.exists("pay.jpg"): image_path = "pay.jpg"
        
        if image_path:
            st.image(image_path, caption="DeepSeek ç®—åŠ›æ”¯æŒ", use_container_width=True)
        else:
            st.info("æš‚æ— å›¾ç‰‡ (è¯·ä¸Šä¼  pay.png)")
            
    st.divider()
    run_switch = st.toggle("æ€»ç”µæº", value=STORE.auto_run)
    with STORE.lock: STORE.auto_run = run_switch

# æ¸²æŸ“åˆ—è¡¨
if st.session_state.view_mode == "lobby":
    for thread in STORE.threads:
        with st.container(border=True):
            c1, c2, c3 = st.columns([1, 8, 2])
            with c1: st.markdown(f"### {thread['avatar']}")
            with c2:
                st.markdown(f"**{thread['title']}**")
                st.caption(f"{thread['time']} | {thread['author']} | {thread['job']}")
            with c3:
                if st.button("å›´è§‚", key=f"btn_{thread['id']}"):
                    st.session_state.view_mode, st.session_state.current_thread_id = "detail", thread['id']
                    st.rerun()

elif st.session_state.view_mode == "detail":
    thread = next((t for t in STORE.threads if t['id'] == st.session_state.current_thread_id), None)
    if thread:
        if st.button("ğŸ”™ è¿”å›"): st.session_state.view_mode = "lobby"; st.rerun()
        st.markdown(f"# {thread['title']}")
        with st.chat_message(thread['author'], avatar=thread['avatar']):
            st.write(thread['content'])
            if thread.get('image_url'): st.markdown(f"![AI]({thread['image_url']})")
        st.divider()
        for c in thread['comments']:
            with st.chat_message(c['name'], avatar=c['avatar']):
                st.write(c['content'])
                st.caption(f"{c['job']} | {c['time']}")
